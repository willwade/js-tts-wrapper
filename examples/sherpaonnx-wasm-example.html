<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SherpaOnnx WebAssembly TTS Example</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
    }
    h1 {
      color: #333;
    }
    textarea {
      width: 100%;
      height: 100px;
      margin-bottom: 10px;
    }
    button {
      padding: 10px 15px;
      background-color: #4CAF50;
      color: white;
      border: none;
      cursor: pointer;
      margin-right: 10px;
    }
    button:hover {
      background-color: #45a049;
    }
    #status {
      margin-top: 20px;
      padding: 10px;
      background-color: #f8f8f8;
      border-left: 4px solid #4CAF50;
    }
    pre {
      background-color: #f5f5f5;
      padding: 10px;
      border-radius: 5px;
      overflow-x: auto;
    }
  </style>
</head>
<body>
  <h1>SherpaOnnx WebAssembly TTS Example</h1>
  
  <div>
    <textarea id="text-to-speak" placeholder="Enter text to speak...">Hello, this is a test of the SherpaOnnx WebAssembly text-to-speech engine.</textarea>
  </div>
  
  <div>
    <button id="speak-button" disabled>Speak</button>
    <button id="stop-button" disabled>Stop</button>
  </div>
  
  <div id="status">Status: Loading...</div>
  
  <pre id="log"></pre>
  
  <!-- Load the SherpaOnnx WebAssembly module -->
  <script src="/public/sherpaonnx-wasm/sherpa-onnx-tts.js"></script>
  <script src="/public/sherpaonnx-wasm/sherpa-onnx-wasm-main-tts.js"></script>
  
  <script>
    // Helper function to log messages
    function log(message) {
      const logElement = document.getElementById('log');
      logElement.textContent += message + '\n';
      console.log(message);
    }
    
    // Helper function to update status
    function updateStatus(message) {
      document.getElementById('status').textContent = 'Status: ' + message;
    }
    
    // Audio context and variables
    let audioContext;
    let audioSource;
    let tts = null;
    
    // Initialize the Module
    Module = {};
    
    // Set up the Module locateFile function
    Module.locateFile = function(path, scriptDirectory = '') {
      log(`locateFile path: ${path}, scriptDirectory: ${scriptDirectory}`);
      return scriptDirectory + path;
    };
    
    // Set up the Module setStatus function
    Module.setStatus = function(status) {
      log(`setStatus: ${status}`);
      if (status === '') {
        updateStatus('WebAssembly module loaded');
      } else {
        updateStatus(status);
      }
    };
    
    // Set up the Module onRuntimeInitialized function
    Module.onRuntimeInitialized = function() {
      log('Module runtime initialized');
      
      try {
        // Initialize audio context
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        log('Audio context initialized');
        
        // Initialize TTS
        log('Initializing TTS...');
        
        // Create TTS configuration
        const offlineTtsVitsModelConfig = {
          model: '/public/sherpaonnx-wasm/model.onnx',
          lexicon: '',
          tokens: '/public/sherpaonnx-wasm/tokens.txt',
          dataDir: '/public/sherpaonnx-wasm/espeak-ng-data',
          dictDir: '',
          noiseScale: 0.667,
          noiseScaleW: 0.8,
          lengthScale: 1.0,
        };
        
        const offlineTtsMatchaModelConfig = {
          acousticModel: '',
          vocoder: '',
          lexicon: '',
          tokens: '',
          dataDir: '',
          dictDir: '',
          noiseScale: 0.667,
          lengthScale: 1.0,
        };
        
        const offlineTtsKokoroModelConfig = {
          model: '',
          voices: '',
          tokens: '',
          dataDir: '',
          lengthScale: 1.0,
          dictDir: '',
          lexicon: '',
        };
        
        const offlineTtsModelConfig = {
          offlineTtsVitsModelConfig: offlineTtsVitsModelConfig,
          offlineTtsMatchaModelConfig: offlineTtsMatchaModelConfig,
          offlineTtsKokoroModelConfig: offlineTtsKokoroModelConfig,
          numThreads: 1,
          debug: 1,
          provider: 'cpu',
        };
        
        const offlineTtsConfig = {
          offlineTtsModelConfig: offlineTtsModelConfig,
          ruleFsts: '',
          ruleFars: '',
          maxNumSentences: 1,
        };
        
        // Create TTS instance
        tts = createOfflineTts(Module, offlineTtsConfig);
        log('TTS initialized');
        log(`Sample rate: ${tts.sampleRate}`);
        log(`Number of speakers: ${tts.numSpeakers}`);
        
        // Enable buttons
        document.getElementById('speak-button').disabled = false;
        document.getElementById('stop-button').disabled = false;
        
        // Update status
        updateStatus('Ready');
      } catch (error) {
        log('Error initializing TTS: ' + error.message);
        updateStatus('Error initializing TTS');
      }
    };
    
    // Speak function
    function speak() {
      log('Speaking...');
      updateStatus('Generating speech...');
      
      try {
        // Get the text to speak
        const text = document.getElementById('text-to-speak').value;
        
        if (!text) {
          log('No text to speak');
          updateStatus('No text to speak');
          return;
        }
        
        // Generate audio
        const audio = tts.generate({
          text: text,
          sid: 0,
          speed: 1.0
        });
        
        log(`Generated audio with sample rate: ${audio.sampleRate} and samples: ${audio.samples.length}`);
        
        // Create an audio buffer
        const audioBuffer = audioContext.createBuffer(1, audio.samples.length, audio.sampleRate);
        const channelData = audioBuffer.getChannelData(0);
        
        // Copy the samples to the audio buffer
        for (let i = 0; i < audio.samples.length; i++) {
          channelData[i] = audio.samples[i];
        }
        
        // Create a source node
        audioSource = audioContext.createBufferSource();
        audioSource.buffer = audioBuffer;
        
        // Connect the source to the destination
        audioSource.connect(audioContext.destination);
        
        // Play the audio
        audioSource.start();
        
        // Update status
        updateStatus('Speaking');
        
        // Add an event listener for when the audio ends
        audioSource.onended = function() {
          updateStatus('Done');
        };
      } catch (error) {
        log('Error speaking: ' + error.message);
        updateStatus('Error speaking');
      }
    }
    
    // Stop function
    function stop() {
      if (audioSource) {
        audioSource.stop();
        updateStatus('Stopped');
      }
    }
    
    // Add event listeners
    document.addEventListener('DOMContentLoaded', function() {
      document.getElementById('speak-button').addEventListener('click', speak);
      document.getElementById('stop-button').addEventListener('click', stop);
    });
    
    // Clean up when the page is unloaded
    window.addEventListener('unload', function() {
      if (tts) {
        try {
          tts.free();
        } catch (error) {
          console.error('Error cleaning up TTS:', error);
        }
      }
    });
  </script>
</body>
</html>
