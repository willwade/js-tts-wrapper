<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SherpaOnnx WebAssembly TTS Direct Test</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
      line-height: 1.6;
    }
    h1 {
      color: #333;
      border-bottom: 2px solid #eee;
      padding-bottom: 10px;
    }
    .container {
      display: flex;
      flex-direction: column;
      gap: 20px;
    }
    .card {
      border: 1px solid #ddd;
      border-radius: 8px;
      padding: 20px;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    .controls {
      display: flex;
      flex-direction: column;
      gap: 15px;
    }
    .control-group {
      display: flex;
      flex-direction: column;
      gap: 5px;
    }
    label {
      font-weight: bold;
      color: #555;
    }
    textarea {
      width: 100%;
      height: 120px;
      padding: 10px;
      border: 1px solid #ccc;
      border-radius: 4px;
      resize: vertical;
    }
    button {
      padding: 10px 15px;
      background-color: #4CAF50;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-weight: bold;
      transition: background-color 0.3s;
    }
    button:hover {
      background-color: #45a049;
    }
    button:disabled {
      background-color: #cccccc;
      cursor: not-allowed;
    }
    .button-group {
      display: flex;
      gap: 10px;
    }
    .log {
      background-color: #f5f5f5;
      border: 1px solid #ddd;
      border-radius: 4px;
      padding: 10px;
      height: 200px;
      overflow-y: auto;
      font-family: monospace;
      white-space: pre-wrap;
    }
    .status {
      font-weight: bold;
      margin-top: 10px;
      color: #555;
    }
    .footer {
      margin-top: 30px;
      text-align: center;
      color: #777;
      font-size: 0.9em;
    }
  </style>
</head>
<body>
  <h1>SherpaOnnx WebAssembly TTS Direct Test</h1>
  
  <div class="container">
    <div class="card">
      <div class="controls">
        <div class="control-group">
          <label for="text">Text to speak:</label>
          <textarea id="text">Hello, this is a test of the SherpaOnnx WebAssembly text-to-speech engine.</textarea>
        </div>
        
        <div class="button-group">
          <button id="speakButton">Speak</button>
          <button id="stopButton" disabled>Stop</button>
          <button id="downloadButton">Download</button>
        </div>
      </div>

      <div class="status" id="status">
        Status: Ready
      </div>

      <div class="log" id="log"></div>
    </div>
  </div>

  <div class="footer">
    Powered by <a href="https://github.com/willwade/js-tts-wrapper" target="_blank">js-tts-wrapper</a> and <a href="https://github.com/k2-fsa/sherpa-onnx" target="_blank">SherpaOnnx</a>
  </div>

  <!-- Load the SherpaOnnx WebAssembly module -->
  <script src="/public/sherpaonnx-wasm/sherpa-onnx-tts.js"></script>
  <script src="/public/sherpaonnx-wasm/sherpa-onnx-wasm-main-tts.js"></script>

  <script>
    // DOM elements
    const textArea = document.getElementById('text');
    const speakButton = document.getElementById('speakButton');
    const stopButton = document.getElementById('stopButton');
    const downloadButton = document.getElementById('downloadButton');
    const statusElement = document.getElementById('status');
    const logElement = document.getElementById('log');

    // Audio context
    let audioContext;
    let audioSource;
    let tts;

    // Log messages
    function log(message) {
      const timestamp = new Date().toLocaleTimeString();
      logElement.textContent += `[${timestamp}] ${message}\n`;
      logElement.scrollTop = logElement.scrollHeight;
      console.log(message);
    }

    // Update status
    function updateStatus(message) {
      statusElement.textContent = `Status: ${message}`;
    }

    // Initialize the TTS
    async function initTTS() {
      try {
        log('Initializing TTS...');
        
        // Wait for the createOfflineTts function to be available
        log('Waiting for createOfflineTts to be available...');
        await new Promise(resolve => {
          const checkCreateOfflineTts = () => {
            if (typeof window.createOfflineTts === 'function' && 
                typeof window.Module !== 'undefined' && 
                window.Module.calledRun) {
              log('createOfflineTts is now available and Module is initialized');
              resolve();
            } else {
              log('Waiting for initialization...');
              log(`createOfflineTts available: ${typeof window.createOfflineTts === 'function'}`);
              log(`Module available: ${typeof window.Module !== 'undefined'}`);
              log(`Module.calledRun: ${window.Module?.calledRun}`);
              setTimeout(checkCreateOfflineTts, 500);
            }
          };
          checkCreateOfflineTts();
        });
        
        // Create the TTS instance
        log('Creating TTS instance...');
        tts = window.createOfflineTts(window.Module);
        log(`TTS created successfully. Sample rate: ${tts.sampleRate}, Num speakers: ${tts.numSpeakers}`);
        
        // Initialize audio context
        log('Initializing audio context...');
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        log('Audio context initialized');
        
        updateStatus('Ready');
      } catch (error) {
        log(`Error initializing TTS: ${error.message}`);
        console.error('Error initializing TTS:', error);
        updateStatus('Error: Failed to initialize TTS');
      }
    }

    // Speak text
    async function speak() {
      try {
        const text = textArea.value.trim();
        if (!text) {
          log('No text to speak');
          return;
        }

        if (!tts) {
          log('TTS not initialized');
          return;
        }

        // Update UI
        updateStatus('Speaking...');
        speakButton.disabled = true;
        stopButton.disabled = false;
        
        log(`Generating audio for text: "${text}"`);
        
        // Generate audio
        const result = tts.generate({ text, sid: 0, speed: 1.0 });
        log(`Generated audio with ${result.samples.length} samples at ${result.sampleRate}Hz`);
        
        // Play audio
        const audioBuffer = audioContext.createBuffer(1, result.samples.length, result.sampleRate);
        audioBuffer.getChannelData(0).set(result.samples);
        
        audioSource = audioContext.createBufferSource();
        audioSource.buffer = audioBuffer;
        audioSource.connect(audioContext.destination);
        
        // Set up event handlers
        audioSource.onended = () => {
          log('Audio playback ended');
          updateStatus('Ready');
          speakButton.disabled = false;
          stopButton.disabled = true;
        };
        
        log('Starting audio playback');
        audioSource.start();
      } catch (error) {
        log(`Error speaking text: ${error.message}`);
        console.error('Error speaking text:', error);
        updateStatus('Error: Failed to speak text');
        speakButton.disabled = false;
        stopButton.disabled = true;
      }
    }

    // Stop speaking
    function stop() {
      if (audioSource) {
        log('Stopping audio playback');
        audioSource.stop();
        audioSource = null;
      }
      
      updateStatus('Ready');
      speakButton.disabled = false;
      stopButton.disabled = true;
    }

    // Download audio
    async function download() {
      try {
        const text = textArea.value.trim();
        if (!text) {
          log('No text to generate audio for');
          return;
        }

        if (!tts) {
          log('TTS not initialized');
          return;
        }

        // Update UI
        updateStatus('Generating audio file...');
        downloadButton.disabled = true;
        
        log(`Generating audio for text: "${text}"`);
        
        // Generate audio
        const result = tts.generate({ text, sid: 0, speed: 1.0 });
        log(`Generated audio with ${result.samples.length} samples at ${result.sampleRate}Hz`);
        
        // Convert to WAV
        const wavBuffer = createWavFile(result.samples, result.sampleRate);
        
        // Create download link
        const blob = new Blob([wavBuffer], { type: 'audio/wav' });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = 'speech.wav';
        a.click();
        
        // Clean up
        setTimeout(() => URL.revokeObjectURL(url), 100);
        
        log('Audio file generated and download started');
        updateStatus('Ready');
        downloadButton.disabled = false;
      } catch (error) {
        log(`Error generating audio file: ${error.message}`);
        console.error('Error generating audio file:', error);
        updateStatus('Error: Failed to generate audio file');
        downloadButton.disabled = false;
      }
    }

    // Create WAV file
    function createWavFile(samples, sampleRate) {
      // Convert Float32Array to Int16Array
      const int16Samples = new Int16Array(samples.length);
      for (let i = 0; i < samples.length; i++) {
        // Scale to 16-bit range and clamp
        const sample = Math.max(-1, Math.min(1, samples[i]));
        int16Samples[i] = Math.floor(sample * 32767);
      }
      
      // Create WAV header
      const wavHeader = new ArrayBuffer(44);
      const view = new DataView(wavHeader);
      
      // "RIFF" chunk descriptor
      view.setUint8(0, "R".charCodeAt(0));
      view.setUint8(1, "I".charCodeAt(0));
      view.setUint8(2, "F".charCodeAt(0));
      view.setUint8(3, "F".charCodeAt(0));
      
      // Chunk size (file size - 8)
      view.setUint32(4, 36 + int16Samples.length * 2, true);
      
      // Format ("WAVE")
      view.setUint8(8, "W".charCodeAt(0));
      view.setUint8(9, "A".charCodeAt(0));
      view.setUint8(10, "V".charCodeAt(0));
      view.setUint8(11, "E".charCodeAt(0));
      
      // "fmt " sub-chunk
      view.setUint8(12, "f".charCodeAt(0));
      view.setUint8(13, "m".charCodeAt(0));
      view.setUint8(14, "t".charCodeAt(0));
      view.setUint8(15, " ".charCodeAt(0));
      
      // Sub-chunk size (16 for PCM)
      view.setUint32(16, 16, true);
      
      // Audio format (1 for PCM)
      view.setUint16(20, 1, true);
      
      // Number of channels (1 for mono)
      view.setUint16(22, 1, true);
      
      // Sample rate
      view.setUint32(24, sampleRate, true);
      
      // Byte rate (sample rate * channels * bytes per sample)
      view.setUint32(28, sampleRate * 1 * 2, true);
      
      // Block align (channels * bytes per sample)
      view.setUint16(32, 1 * 2, true);
      
      // Bits per sample
      view.setUint16(34, 16, true);
      
      // "data" sub-chunk
      view.setUint8(36, "d".charCodeAt(0));
      view.setUint8(37, "a".charCodeAt(0));
      view.setUint8(38, "t".charCodeAt(0));
      view.setUint8(39, "a".charCodeAt(0));
      
      // Sub-chunk size (number of samples * channels * bytes per sample)
      view.setUint32(40, int16Samples.length * 1 * 2, true);
      
      // Combine header and samples
      const wavBuffer = new Uint8Array(wavHeader.byteLength + int16Samples.length * 2);
      wavBuffer.set(new Uint8Array(wavHeader), 0);
      wavBuffer.set(new Uint8Array(int16Samples.buffer), wavHeader.byteLength);
      
      return wavBuffer;
    }

    // Event listeners
    speakButton.addEventListener('click', speak);
    stopButton.addEventListener('click', stop);
    downloadButton.addEventListener('click', download);

    // Initialize TTS when the page loads
    window.addEventListener('DOMContentLoaded', initTTS);
  </script>
</body>
</html>
